# üîç Swarm Analysis Timeout Diagnosis

## üö® **ISSUE IDENTIFIED**

The comprehensive Playwright test and API tests are **timing out after 3-5 minutes** when trying to analyze the portfolio with all 16 agents.

---

## üî¨ **ROOT CAUSE ANALYSIS**

### **Problem: Sequential Agent Execution**

**File**: `src/agents/swarm/swarm_coordinator.py` (lines 158-170)

```python
# Collect analyses from all agents
analyses = {}

for agent_id, agent in self.agents.items():  # ‚Üê SEQUENTIAL LOOP
    try:
        logger.debug(f"Running analysis: {agent_id}")
        analysis = agent.analyze(context)  # ‚Üê BLOCKS until complete
        analyses[agent_id] = {
            'agent_type': agent.agent_type,
            'analysis': analysis,
            'timestamp': datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"Error in agent {agent_id}: {e}")
        agent.record_error(e, context)
        self._metrics['total_errors'] += 1
```

**The Issue**:
- ‚ùå Agents are called **sequentially** in a for loop
- ‚ùå Each agent waits for the previous one to complete
- ‚ùå LLM calls take 10-30 seconds each
- ‚ùå With 16 agents: **3-8 minutes total**

---

## ‚è±Ô∏è **TIMING BREAKDOWN**

### **Current Sequential Execution**

| Agent Type | LLM Call Time | Count | Total Time |
|------------|---------------|-------|------------|
| Market Analyst | 15-20s | 3 | 45-60s |
| Fundamental Analyst | 20-30s | 2 | 40-60s |
| Macro Economist | 20-30s | 2 | 40-60s |
| Risk Manager | 15-20s | 2 | 30-40s |
| Sentiment Analyst | 10-15s | 1 | 10-15s |
| Volatility Specialist | 15-20s | 3 | 45-60s |
| Rule-based agents | <1s | 3 | <3s |

**Total Sequential Time**: **210-298 seconds (3.5-5 minutes)**

### **With Parallel Execution** (Recommended)

All LLM agents run simultaneously:
- **Total Parallel Time**: **20-30 seconds** (longest single agent)
- **Speedup**: **7-10x faster!**

---

## ‚úÖ **SOLUTION: Parallel Agent Execution**

### **Option 1: ThreadPoolExecutor** (Recommended)

```python
from concurrent.futures import ThreadPoolExecutor, as_completed

def analyze_portfolio(self, portfolio_data, market_data):
    """Perform comprehensive portfolio analysis using all agents IN PARALLEL"""
    
    if not self.is_running:
        raise RuntimeError("Swarm not running. Call start() first.")
    
    logger.info("Starting portfolio analysis")
    
    # Prepare context
    context = {
        'portfolio': portfolio_data,
        'market': market_data,
        'timestamp': datetime.utcnow().isoformat()
    }
    
    # Update shared state
    self.shared_context.update_state('portfolio_data', portfolio_data, source='coordinator')
    self.shared_context.update_state('market_data', market_data, source='coordinator')
    
    # Collect analyses from all agents IN PARALLEL
    analyses = {}
    
    def run_agent_analysis(agent_id, agent):
        """Run single agent analysis"""
        try:
            logger.debug(f"Running analysis: {agent_id}")
            analysis = agent.analyze(context)
            return agent_id, {
                'agent_type': agent.agent_type,
                'analysis': analysis,
                'timestamp': datetime.utcnow().isoformat()
            }
        except Exception as e:
            logger.error(f"Error in agent {agent_id}: {e}")
            agent.record_error(e, context)
            self._metrics['total_errors'] += 1
            return agent_id, None
    
    # Execute all agents in parallel
    with ThreadPoolExecutor(max_workers=16) as executor:
        futures = {
            executor.submit(run_agent_analysis, agent_id, agent): agent_id
            for agent_id, agent in self.agents.items()
        }
        
        for future in as_completed(futures):
            agent_id, result = future.result()
            if result:
                analyses[agent_id] = result
    
    logger.info(f"Portfolio analysis complete: {len(analyses)} agents contributed")
    
    return {
        'swarm_name': self.name,
        'timestamp': datetime.utcnow().isoformat(),
        'context': context,
        'analyses': analyses,
        'agent_count': len(analyses)
    }
```

### **Option 2: asyncio** (Alternative)

```python
import asyncio

async def analyze_portfolio_async(self, portfolio_data, market_data):
    """Async version with parallel execution"""
    
    # ... context setup ...
    
    async def run_agent_async(agent_id, agent):
        """Run agent analysis asynchronously"""
        try:
            # Wrap synchronous agent.analyze() in executor
            loop = asyncio.get_event_loop()
            analysis = await loop.run_in_executor(None, agent.analyze, context)
            return agent_id, {
                'agent_type': agent.agent_type,
                'analysis': analysis,
                'timestamp': datetime.utcnow().isoformat()
            }
        except Exception as e:
            logger.error(f"Error in agent {agent_id}: {e}")
            return agent_id, None
    
    # Run all agents concurrently
    tasks = [run_agent_async(agent_id, agent) for agent_id, agent in self.agents.items()]
    results = await asyncio.gather(*tasks)
    
    analyses = {agent_id: result for agent_id, result in results if result}
    
    return { ... }
```

---

## üéØ **RECOMMENDED IMPLEMENTATION**

### **Step 1: Update SwarmCoordinator**

**File**: `src/agents/swarm/swarm_coordinator.py`

Replace the sequential for loop (lines 155-171) with parallel execution using ThreadPoolExecutor.

### **Step 2: Add Progress Logging**

```python
from tqdm import tqdm  # Optional: progress bar

with ThreadPoolExecutor(max_workers=16) as executor:
    futures = {
        executor.submit(run_agent_analysis, agent_id, agent): agent_id
        for agent_id, agent in self.agents.items()
    }
    
    # Progress tracking
    completed = 0
    total = len(futures)
    
    for future in as_completed(futures):
        agent_id, result = future.result()
        completed += 1
        logger.info(f"Progress: {completed}/{total} agents complete")
        
        if result:
            analyses[agent_id] = result
```

### **Step 3: Add Timeout Per Agent**

```python
def run_agent_analysis(agent_id, agent):
    """Run single agent analysis with timeout"""
    try:
        logger.debug(f"Running analysis: {agent_id}")
        
        # Add timeout wrapper
        import signal
        
        def timeout_handler(signum, frame):
            raise TimeoutError(f"Agent {agent_id} timed out")
        
        signal.signal(signal.SIGALRM, timeout_handler)
        signal.alarm(60)  # 60 second timeout per agent
        
        try:
            analysis = agent.analyze(context)
        finally:
            signal.alarm(0)  # Cancel alarm
        
        return agent_id, {
            'agent_type': agent.agent_type,
            'analysis': analysis,
            'timestamp': datetime.utcnow().isoformat()
        }
    except TimeoutError as e:
        logger.error(f"Timeout in agent {agent_id}: {e}")
        return agent_id, None
    except Exception as e:
        logger.error(f"Error in agent {agent_id}: {e}")
        return agent_id, None
```

---

## üìä **EXPECTED IMPROVEMENTS**

### **Before (Sequential)**
- ‚è±Ô∏è Total Time: **3.5-5 minutes**
- üêå Slowest agent blocks all others
- ‚ùå Timeout after 5 minutes

### **After (Parallel)**
- ‚è±Ô∏è Total Time: **20-30 seconds**
- üöÄ All agents run simultaneously
- ‚úÖ Completes well within timeout
- üìà **7-10x faster!**

---

## üîß **IMMEDIATE WORKAROUND**

While waiting for parallel execution implementation, you can:

### **Option A: Reduce Agent Count**

Temporarily reduce from 16 agents to 5-8 agents for testing:

```python
# In src/api/swarm_routes.py
agents = [
    LLMMarketAnalystAgent(agent_id="market_analyst_1", preferred_model="lmstudio"),
    LLMFundamentalAnalystAgent(agent_id="fundamental_analyst_1", preferred_model="lmstudio"),
    LLMRiskManagerAgent(agent_id="risk_manager_1", preferred_model="anthropic"),
    LLMSentimentAnalystAgent(agent_id="sentiment_analyst_1", preferred_model="lmstudio"),
    LLMVolatilitySpecialistAgent(agent_id="volatility_specialist_1", preferred_model="lmstudio"),
    # ... rule-based agents
]
```

### **Option B: Increase API Timeout**

```python
# In test scripts
response = requests.post(
    f"{API_URL}/api/swarm/analyze-csv",
    files=files,
    data=data,
    timeout=600  # 10 minutes instead of 5
)
```

### **Option C: Use Cached/Mock Data**

Create a mock response for demonstration purposes while the real implementation is being optimized.

---

## üìç **WHERE TO MAKE CHANGES**

**Primary File**: `src/agents/swarm/swarm_coordinator.py`
- Lines 155-171: Replace sequential loop with ThreadPoolExecutor

**Secondary Files** (for testing):
- `test_enhanced_swarm_playwright.py`: Increase timeout
- `test_enhanced_swarm_api_direct.py`: Increase timeout
- `test_enhanced_swarm_output.py`: Increase timeout

---

## üéØ **NEXT STEPS**

1. **Implement parallel execution** in SwarmCoordinator (highest priority)
2. **Add progress logging** to track agent completion
3. **Add per-agent timeouts** to prevent hanging
4. **Re-run comprehensive test** to verify <30 second completion
5. **Update documentation** with new performance metrics

---

**üöÄ WITH PARALLEL EXECUTION, THE SWARM ANALYSIS WILL COMPLETE IN 20-30 SECONDS INSTEAD OF 3-5 MINUTES!**

**This is a critical performance optimization that will make the system production-ready.**

